{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data successfully converted to CSV.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Specify the JSON file path\n",
    "json_file_path = r\"C:\\ineuron\\Resources\\ResumeParser\\merged.json\"\n",
    "\n",
    "# Specify the CSV file path\n",
    "csv_file_path = r\"C:\\ineuron\\Resources\\ResumeParser\\data.csv\"\n",
    "\n",
    "import json\n",
    "import csv\n",
    "\n",
    "# Load JSON data from a file\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(csv_file_path, mode='w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "\n",
    "    # Write the header row\n",
    "    writer.writerow(['Name', 'Email', 'Phone_Number', 'Designations', 'Companies', 'Total_Year_Experience', 'Skills', 'Certifications', 'College_Degree', 'Publications'])\n",
    "\n",
    "    # Write the data rows\n",
    "    for json_entry in data.values():\n",
    "        name = json_entry['name']\n",
    "        email = json_entry['email']\n",
    "        phone_number = json_entry['phone_number']\n",
    "        designations = ', '.join(json_entry['designations'])\n",
    "        companies = ', '.join(json_entry['companies'])\n",
    "        total_year_experience = json_entry['total_year_experience']\n",
    "        skills = ', '.join(json_entry['skills'])\n",
    "        certifications = ', '.join(json_entry['certifications'])\n",
    "        college_degree = json_entry['college_degree']\n",
    "        publications = ', '.join(json_entry['publications'])\n",
    "\n",
    "        writer.writerow([name, email, phone_number, designations, companies, total_year_experience, skills, certifications, college_degree, publications])\n",
    "\n",
    "print(\"JSON data successfully converted to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt and completion pairs have been saved to: resume_prompt_completions.jsonl\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_file_path = \"data.csv\"\n",
    "\n",
    "# Separator for prompts\n",
    "separator = \"\\n\\n###\\n\\n\"\n",
    "\n",
    "# Stop sequence for completions\n",
    "stop_sequence = \"\\n\"\n",
    "\n",
    "# List to store prompt and completion pairs\n",
    "prompt_completion_pairs = []\n",
    "\n",
    "# Read the CSV file\n",
    "with open(csv_file_path, newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    \n",
    "    # Iterate over each row in the CSV file\n",
    "    for row in reader:\n",
    "        resume_text = row['Resume_Text']\n",
    "        \n",
    "        # Create the prompt text\n",
    "        prompt_text = f'{resume_text}{separator}'\n",
    "\n",
    "        # Create the completion text using remaining columns\n",
    "        completion_text = f' {json.dumps({k: v for k, v in row.items() if k != \"Resume_Text\"})[1:-1]}{stop_sequence}'\n",
    "        \n",
    "        # Create prompt and completion pair\n",
    "        prompt_completion_pairs.append({\"prompt\": prompt_text, \"completion\": completion_text})\n",
    "\n",
    "# Write the generated prompt and completion pairs to a JSONL file\n",
    "output_file_path = \"resume_prompt_completions.jsonl\"  # Update the file path and name if needed\n",
    "with open(output_file_path, 'w') as outfile:\n",
    "    for pair in prompt_completion_pairs:\n",
    "        outfile.write(json.dumps(pair) + '\\n')\n",
    "\n",
    "print(f\"Prompt and completion pairs have been saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text= '''Chinta Krishna Mourya\n",
    "mouryachinta19@gmail.com | +91-7793981667 | +91-9346074972\n",
    "EDUCATION\n",
    "IIT KHARAGPUR\n",
    "BTech in Ocean Engineering\n",
    "MAY 2021 | West Bengal\n",
    "CGPA: 6.59 / 10\n",
    "BIIT JR. COLLEGE\n",
    "Intermediate-MPC\n",
    "March 2017 | Andhra Pradesh\n",
    "Percentage : 98.2\n",
    "BHASHYAM HIGH SCHOOL\n",
    "April 2015 | Andhra Pradesh\n",
    "GPA : 9.8\n",
    "LINKS\n",
    "•LinkedIn:\n",
    "https://www.linkedin.com/in/chinta\u0002krishna-mourya-949aab178/\n",
    "•GitHub:\n",
    "https://github.com/ChintaKrishnaMourya\n",
    "SKILLS\n",
    "•Machine Learning •Natural Language\n",
    "Processing •Python •Neural Network\n",
    "•Statistical Modeling •SQL •Flask\n",
    "•Predictive Modeling •Statistics •Data\n",
    "Wrangling •Data Visualization •GIT\n",
    "•Prompt Engineering.\n",
    "CERTIFICATIONS\n",
    "Udemy - Machine Learning A-Z Python in\n",
    "Data Science (link)\n",
    "iNeuron - Full Stack Data Science\n",
    "Bootcamp (link)\n",
    "LANGUAGES\n",
    "• English (Fluent)\n",
    "• Telugu (Native)\n",
    "• Hindi (Beginner)\n",
    "EXTRACURRICULAR\n",
    "ACTIVITIES\n",
    "• Stood 1st in Quiz conducted by SBI\n",
    "YONO in Kolkata in 2018. • Volunteered\n",
    "in multiple social service programs\n",
    "organized by ”AACHARANA Charitable\n",
    "trust”. • Organized and conducted a\n",
    "town-level competitive exam for 200 10th\n",
    "class students. • Participated in various\n",
    "activities as an NSS candidate during\n",
    "college.\n",
    "EXPERIENCE\n",
    "INEURON.AI | Data Science Intern (link)\n",
    "Jan 2023 – Apr 2023\n",
    "• Developed end-to-end credit card default prediction model (project link) using\n",
    "Python and ML tools.\n",
    "• Conducted EDA, data preprocessing, and model selection with optimized\n",
    "Python code and logging. Out of ”SVM”, ”LogisticRegression”, ”DecisionTree”,\n",
    "”RandomForest”, ”Naive Baye” classifiers ”Random Forest” performed better\n",
    "with F1 score 0.86.\n",
    "• Designed project architecture and built Flask web app, deployed on AWS EC2\n",
    "for user access. Gained experience in various ML techniques, Python\n",
    "programming, deployment.\n",
    "BLUEAI-LABS | Freelance AI Engineer\n",
    "Apr 2023 - May 2023\n",
    "• Built a resume parser using pyresparser to extract essential details from\n",
    "multiple resumes, generating a CSV file for analysis.\n",
    "• Developed functions utilizing the OpenAI API, prompt engineering for\n",
    "scorecard generation based on job descriptions and candidate qualifications,\n",
    "evaluating resumes, generating summaries providing coding assessment\n",
    "questions and interview question generation.\n",
    "• Gained experience understanding of different models like ada, babbage, curie,\n",
    "davinci, and concepts of Large Language Models (LLMs).\n",
    "PROJECTS\n",
    "FLAT RESALE PRICE PREDICTION (link) Nov 2022 – Nov 2022\n",
    "• Conducted EDA, performed feature engineering statistical analysis, including\n",
    "chi-square tests, utilized heatmaps to identify correlations among features.\n",
    "• Trained fourregression models - Random Forest Regressor, XGBoost\n",
    "Regressor, Decision Tree Regressor and Neural Network - and compared their\n",
    "performance.\n",
    "• Identified that the Random Forest Regressor model outperformed the others\n",
    "with R2 score 0.96 and used it to predict flatresale prices. XGBoost gave\n",
    "0.951, DecisionTree gave 0.94 and Neural Network with relative error 0.04.\n",
    "CRACK DEPTH PREDICTION OF ABAQUS MODEL (link) Aug 2020 –\n",
    "Dec 2020\n",
    "• Analyzed cracks of varying depths in Abaqus software and extracted\n",
    "corresponding strain values merged multiple datasets to create a\n",
    "comprehensive dataset with crack depth as the target variable and strain values\n",
    "from four sensors as the independent variables.\n",
    "• Trained Random Forest Regression and Linear Regression algorithms to\n",
    "predict crack depth and obtained an impressive RMSE of 0.0007 by Random\n",
    "Forest Regressor.\n",
    "MALL CUSTOMERS SEGMENTATION (link) Dec 2022 – Dec 2022\n",
    "• Conducted EDA Performed customer segmentation using KMeans clustering\n",
    "algorithm. Used WCSS, kneed library , Gap Statistic , DBSCAN to determine\n",
    "the optimal number of clusters.\n",
    "• Plotted the clusters using Annual income vs Spending score- silhouette score -\n",
    "0.55 and Income vs Age vs Spending score - silhouette score - 0.45.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'''Give Name, EMail, Phone_Number, Designation, Companies, Total_Year_experience, Skills, Certifications, College_Degree, Publications, Social_Links\\\n",
    "from this resume_text.\n",
    "resume_text = ```{resume_text}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7W2vr8GxObFqgKanGqwIBDDeKH5Jz at 0x19edf378db0> JSON: {\n",
       "  \"id\": \"cmpl-7W2vr8GxObFqgKanGqwIBDDeKH5Jz\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1687872123,\n",
       "  \"model\": \"curie:ft-personal-2023-06-27-08-10-50\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"\\n\\u2022 Used KMeans clustering algorithm with a grid size \\u03c4 = 25\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"length\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 1103,\n",
       "    \"completion_tokens\": 16,\n",
       "    \"total_tokens\": 1119\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "openai.Completion.create(\n",
    "    model=\"curie:ft-personal-2023-06-27-08-10-50\",\n",
    "    prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
